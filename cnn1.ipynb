{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/riktim/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPool1D, Dropout, concatenate\n",
    "from keras.preprocessing import text as keras_text, sequence as keras_seq\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.cross_validation import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# define network parameters\n",
    "max_features = 64\n",
    "maxlen = 900\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'CCCCCCCCCCCCCCCCCCCCCCCHHHHHHHHHHHHHHHHHCCCCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'CCCHHHHHHHHHHHHHHHHHHCHHHHHHHHHHHHHHHHHCHHHHH...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             pattern\n",
       "0  'CCCCCCCCCCCCCCCCCCCCCCCHHHHHHHHHHHHHHHHHCCCCC...\n",
       "1  'CCCHHHHHHHHHHHHHHHHHHCHHHHHHHHHHHHHHHHHCHHHHH..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat=pd.read_csv('string.csv',names = [\"pattern\"])\n",
    "pat.head(2)\n",
    "#print(len(df[\"pattern\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>'1ab3A.secstr'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>'1abvA.secstr'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class       file_name\n",
       "0      1  '1ab3A.secstr'\n",
       "1      1  '1abvA.secstr'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_file_name=pd.read_csv('id_label.csv',names = [\"class\", \"file_name\"])\n",
    "class_file_name.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame()\n",
    "data['pattern']=pat['pattern']\n",
    "data['class_no']=class_file_name['class']\n",
    "data['pattern']=[s[1:-1] for s in data.pattern]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>class_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>CCCCEEEEEEEECCCCCCCCCCEEEEEECCCCCEEECCCHHHHHHH...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>CCCCCCCCCCCCCCCCEEEEEECHHHCCCEECCCCCCCCCCCCCEE...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>CEEEEEECCHHHHHHHCCCCCEEEEECCCCCCCCEEEEEEECCCCC...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>CCCCCCCCCCCCCCCCCCCCCCHHHHHHHHHHHHHHCCEEEEEEEC...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>CCCHHHHHHHHHCCCCCCCCCCCHHHHHHHHHHCCCCCCCCCEEEE...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               pattern  class_no\n",
       "546  CCCCEEEEEEEECCCCCCCCCCEEEEEECCCCCEEECCCHHHHHHH...         4\n",
       "547  CCCCCCCCCCCCCCCCEEEEEECHHHCCCEECCCCCCCCCCCCCEE...         4\n",
       "548  CEEEEEECCHHHHHHHCCCCCEEEEECCCCCCCCEEEEEEECCCCC...         4\n",
       "549  CCCCCCCCCCCCCCCCCCCCCCHHHHHHHHHHHHHHCCEEEEEEEC...         4\n",
       "550  CCCHHHHHHHHHCCCCCCCCCCCHHHHHHHHHHCCCCCCCCCEEEE...         4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.pattern\n",
    "Y = data.class_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(Y_train))\n",
    "#print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 678 µs, sys: 0 ns, total: 678 µs\n",
      "Wall time: 686 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "list_sentences_train = X_train.values\n",
    "list_classes = list(set(Y_train))\n",
    "y = Y_train.values\n",
    "y_val=[val-1 for val in y]\n",
    "list_sentences_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_sentences_train[0])\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(st)\n",
    "#print(list_sentences_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras_text.Tokenizer(char_level = True)\n",
    "tokenizer.fit_on_texts(list_sentences_train)\n",
    "# train data\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "#print(list_tokenized_train[0])\n",
    "X_t = keras_seq.pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "# test data\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "X_te = keras_seq.pad_sequences(list_tokenized_test, maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y = to_categorical(y_val)\n",
    "#test_classes = to_categorical(test_class_list)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 256)    1024        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 256)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "word_fcl_0 (Conv1D)             (None, None, 16)     4112        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ngram_2_cnn_0 (Conv1D)          (None, None, 16)     12304       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ngram_4_cnn_0 (Conv1D)          (None, None, 16)     12304       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ngram_8_cnn_0 (Conv1D)          (None, None, 16)     12304       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ngram_16_cnn_0 (Conv1D)         (None, None, 16)     12304       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "word_fcl_1 (Conv1D)             (None, None, 32)     544         word_fcl_0[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "ngram_2_cnn_1 (Conv1D)          (None, None, 32)     1568        ngram_2_cnn_0[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "ngram_4_cnn_1 (Conv1D)          (None, None, 32)     1568        ngram_4_cnn_0[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "ngram_8_cnn_1 (Conv1D)          (None, None, 32)     1568        ngram_8_cnn_0[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "ngram_16_cnn_1 (Conv1D)         (None, None, 32)     1568        ngram_16_cnn_0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 32)           0           word_fcl_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 32)           0           ngram_2_cnn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 32)           0           ngram_4_cnn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 32)           0           ngram_8_cnn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 32)           0           ngram_16_cnn_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32)           0           global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32)           0           global_max_pooling1d_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 160)          0           dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           10304       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            132         dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 73,684\n",
      "Trainable params: 73,684\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(conv_layers = 2, \n",
    "                dilation_rates = [0, 2, 4, 8, 16], \n",
    "                embed_size = 256):\n",
    "    inp = Input(shape=(None, ))\n",
    "    x = Embedding(input_dim = len(tokenizer.word_counts)+1, \n",
    "                  output_dim = embed_size)(inp)\n",
    "    prefilt_x = Dropout(0.25)(x)\n",
    "    out_conv = []\n",
    "    # dilation rate lets us use ngrams and skip grams to process \n",
    "    for dilation_rate in dilation_rates:\n",
    "        x = prefilt_x\n",
    "        for i in range(2):\n",
    "            if dilation_rate>0:\n",
    "                x = Conv1D(16*2**(i), \n",
    "                           kernel_size = 3, \n",
    "                           dilation_rate = dilation_rate,\n",
    "                          activation = 'relu',\n",
    "                          name = 'ngram_{}_cnn_{}'.format(dilation_rate, i)\n",
    "                          )(x)\n",
    "            else:\n",
    "                x = Conv1D(16*2**(i), \n",
    "                           kernel_size = 1,\n",
    "                          activation = 'relu',\n",
    "                          name = 'word_fcl_{}'.format(i))(x)\n",
    "        out_conv += [Dropout(0.5)(GlobalMaxPool1D()(x))]\n",
    "    x = concatenate(out_conv, axis = -1)    \n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(4, activation='softmax')(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (374, 900)\n",
      "Testing: (94, 900)\n",
      "(468, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#any_category_positive = np.sum(y,1)\n",
    "#print('Distribution of Total Positive Labels (important for validation)')\n",
    "#print(pd.value_counts(any_category_positive))\n",
    "X_t_train, X_t_test, y_train, y_test = train_test_split(X_t, y, \n",
    "                                                        test_size = 0.2,\n",
    "                                                       random_state = 2017)\n",
    "print('Training:', X_t_train.shape)\n",
    "print('Testing:', X_t_test.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 374 samples, validate on 94 samples\n",
      "Epoch 1/10\n",
      "374/374 [==============================] - 4s 10ms/step - loss: 1.2389 - acc: 0.4733 - val_loss: 0.9942 - val_acc: 0.5957\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.99417, saving model to best_weights.h5\n",
      "Epoch 2/10\n",
      "374/374 [==============================] - 3s 9ms/step - loss: 1.0399 - acc: 0.5455 - val_loss: 0.9411 - val_acc: 0.5957\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.99417 to 0.94105, saving model to best_weights.h5\n",
      "Epoch 3/10\n",
      "374/374 [==============================] - 4s 10ms/step - loss: 0.9981 - acc: 0.5535 - val_loss: 0.8847 - val_acc: 0.5851\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.94105 to 0.88466, saving model to best_weights.h5\n",
      "Epoch 4/10\n",
      "374/374 [==============================] - 3s 9ms/step - loss: 0.9226 - acc: 0.6283 - val_loss: 0.9029 - val_acc: 0.6489\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.88466\n",
      "Epoch 5/10\n",
      "374/374 [==============================] - 4s 10ms/step - loss: 0.9054 - acc: 0.6016 - val_loss: 0.8945 - val_acc: 0.6489\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.88466\n",
      "Epoch 6/10\n",
      "374/374 [==============================] - 5s 12ms/step - loss: 0.8692 - acc: 0.6257 - val_loss: 0.8328 - val_acc: 0.6809\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.88466 to 0.83280, saving model to best_weights.h5\n",
      "Epoch 7/10\n",
      "374/374 [==============================] - 4s 10ms/step - loss: 0.8576 - acc: 0.6417 - val_loss: 0.8151 - val_acc: 0.6915\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.83280 to 0.81509, saving model to best_weights.h5\n",
      "Epoch 8/10\n",
      "374/374 [==============================] - 4s 10ms/step - loss: 0.8344 - acc: 0.6711 - val_loss: 0.7873 - val_acc: 0.7128\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.81509 to 0.78729, saving model to best_weights.h5\n",
      "Epoch 9/10\n",
      "374/374 [==============================] - 4s 10ms/step - loss: 0.8110 - acc: 0.6497 - val_loss: 0.8057 - val_acc: 0.6915\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.78729\n",
      "Epoch 10/10\n",
      "374/374 [==============================] - 4s 11ms/step - loss: 0.7697 - acc: 0.6872 - val_loss: 0.7523 - val_acc: 0.7553\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.78729 to 0.75230, saving model to best_weights.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcdcfc9d160>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4 # large enough that some other labels come in\n",
    "epochs = 1\n",
    "\n",
    "file_path=\"best_weights.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20)\n",
    "\n",
    "callbacks_list = [checkpoint, early] #early\n",
    "model.fit(X_t_train, y_train, \n",
    "          validation_data=(X_t_test, y_test),\n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          shuffle = True,\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
