{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/riktim/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.layers import Input, Embedding, Activation, Flatten, Dense,LSTM,Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from sklearn.cross_validation import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'CCCCCCCCCCCCCCCCCCCCCCCHHHHHHHHHHHHHHHHHCCCCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'CCCHHHHHHHHHHHHHHHHHHCHHHHHHHHHHHHHHHHHCHHHHH...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             pattern\n",
       "0  'CCCCCCCCCCCCCCCCCCCCCCCHHHHHHHHHHHHHHHHHCCCCC...\n",
       "1  'CCCHHHHHHHHHHHHHHHHHHCHHHHHHHHHHHHHHHHHCHHHHH..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat=pd.read_csv('string.csv',names = [\"pattern\"])\n",
    "pat.head(2)\n",
    "#print(len(df[\"pattern\"][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>'1ab3A.secstr'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>'1abvA.secstr'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class       file_name\n",
       "0      1  '1ab3A.secstr'\n",
       "1      1  '1abvA.secstr'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_file_name=pd.read_csv('id_label.csv',names = [\"class\", \"file_name\"])\n",
    "class_file_name.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 551 entries, 0 to 550\n",
      "Data columns (total 1 columns):\n",
      "pattern    551 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 4.4+ KB\n"
     ]
    }
   ],
   "source": [
    "pat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>'CCEEEEEECCCHHHHHHHHHHHHHHHHHCCCCEEEEEECCCHHHH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  pattern\n",
       "count                                                 551\n",
       "unique                                                551\n",
       "top     'CCEEEEEECCCHHHHHHHHHHHHHHHHHCCCCEEEEEECCCHHHH...\n",
       "freq                                                    1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame()\n",
    "data['pattern']=pat['pattern']\n",
    "data['class_no']=class_file_name['class']\n",
    "data['pattern']=[s[1:-1] for s in data.pattern]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>class_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>CCCCEEEEEEEECCCCCCCCCCEEEEEECCCCCEEECCCHHHHHHH...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>CCCCCCCCCCCCCCCCEEEEEECHHHCCCEECCCCCCCCCCCCCEE...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>CEEEEEECCHHHHHHHCCCCCEEEEECCCCCCCCEEEEEEECCCCC...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>CCCCCCCCCCCCCCCCCCCCCCHHHHHHHHHHHHHHCCEEEEEEEC...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>CCCHHHHHHHHHCCCCCCCCCCCHHHHHHHHHHCCCCCCCCCEEEE...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               pattern  class_no\n",
       "546  CCCCEEEEEEEECCCCCCCCCCEEEEEECCCCCEEECCCHHHHHHH...         4\n",
       "547  CCCCCCCCCCCCCCCCEEEEEECHHHCCCEECCCCCCCCCCCCCEE...         4\n",
       "548  CEEEEEECCHHHHHHHCCCCCEEEEECCCCCCCCEEEEEEECCCCC...         4\n",
       "549  CCCCCCCCCCCCCCCCCCCCCCHHHHHHHHHHHHHHCCEEEEEEEC...         4\n",
       "550  CCCHHHHHHHHHCCCCCCCCCCCHHHHHHHHHHCCCCCCCCCEEEE...         4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 551 entries, 0 to 550\n",
      "Data columns (total 2 columns):\n",
      "pattern     551 non-null object\n",
      "class_no    551 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 8.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.pattern\n",
    "Y = data.class_no\n",
    "#le = LabelEncoder()\n",
    "#Y = le.fit_transform(Y)\n",
    "#Y = Y.reshape(-1,1)\n",
    "X=[s.lower() for s in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccccccccccccccccccccccchhhhhhhhhhhhhhhhhcccccccccccccccccchhhccchhhchhhhcchhhcchhhcccccc\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = Tokenizer(num_words=None, char_level=True, oov_token='UNK')\n",
    "tk.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cchhhhhhhhhhhhhhhccccccchhhhhhhhhhhhhhhccchhhhhhhhhhhhhhhccccchhhhhhhhhhhhhhhhhhhhhhhhhhhhhhccccccchhhhhhhhhhhhhhhhhhhhhhhhhcccccchhhhhhhhhhhhhhhhhhhhhhhhhhhhccchhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhcccchhhhhhhhhhhhhhhhhhhhhhhchhhhcccccccceeccccceeecccccccccccccccchhhhhhccccccccceeeeeeeeeeeecccccccceeeeeeeeeeeecccccccceeccceecccceeeeeeeccceeeeeeeeeeeeeeecceeeeeeeeeeeeeeecccceeeeeeeecccccceeeeehhhcccccccccchhhhcceeeeeeeeeecccccceeeeeeeeeccccccceecccceeeeehhhcceeccceeeeccccccccceeeeccceeeeeeeceecccccceeeeeeeeeeccceeeeeeecceeeeeeeeccccccccccchhhceeeecccceecccceeeeeeeccccccceeeeeeeeeeec'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alphabet = \"abcdefghijklmnopqrstuvwxyz0123456789,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\n",
    "alphabet=\"abcdefghijklmnopqrstuvwxyz\"\n",
    "char_dict = {}\n",
    "for i, char in enumerate(alphabet):\n",
    "    char_dict[char] = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#char_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use char_dict to replace the tk.word_index\n",
    "tk.word_index = char_dict.copy()\n",
    "# Add 'UNK' to the vocabulary\n",
    "tk.word_index[tk.oov_token] = max(char_dict.values()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string to index\n",
    "train_sequences = tk.texts_to_sequences(X_train)\n",
    "test_texts = tk.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'len'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-af05613ace83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'len'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Padding\n",
    "train_data = pad_sequences(train_sequences, maxlen=900, padding='post')\n",
    "test_data = pad_sequences(test_texts, maxlen=900, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "train_data = np.array(train_data, dtype='float32')\n",
    "test_data = np.array(test_data, dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(468, 900)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape\n",
    "#print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = Y_train.values\n",
    "train_class_list = [x - 1 for x in train_classes]\n",
    "\n",
    "test_classes = Y_test.values\n",
    "test_class_list = [x - 1 for x in test_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(468,)\n"
     ]
    }
   ],
   "source": [
    "print(train_classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_classes = to_categorical(train_class_list)\n",
    "test_classes = to_categorical(test_class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 900)               0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 900, 27)           756       \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 894, 256)          48640     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 894, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 298, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 292, 256)          459008    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 292, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 97, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 95, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 95, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 93, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 93, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 91, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 91, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 89, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 89, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 29, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 7424)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              7603200   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 9,952,760\n",
      "Trainable params: 9,952,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = 900\n",
    "max_len=input_size\n",
    "vocab_size = len(tk.word_index)\n",
    "#embedding_size = 69\n",
    "embedding_size=27\n",
    "conv_layers = [[256, 7, 3],\n",
    "               [256, 7, 3],\n",
    "               [256, 3, -1],\n",
    "               [256, 3, -1],\n",
    "               [256, 3, -1],\n",
    "               [256, 3, 3]]\n",
    "\n",
    "fully_connected_layers = [1024, 1024]\n",
    "num_of_classes = 4\n",
    "dropout_p = 0.5\n",
    "optimizer = 'adam'\n",
    "loss = 'categorical_crossentropy'\n",
    "\n",
    "# Embedding weights\n",
    "embedding_weights = []  # (70, 69)\n",
    "embedding_weights.append(np.zeros(vocab_size))  # (0, 69)\n",
    "\n",
    "for char, i in tk.word_index.items():  # from index 1 to 69\n",
    "    onehot = np.zeros(vocab_size)\n",
    "    onehot[i - 1] = 1\n",
    "    embedding_weights.append(onehot)\n",
    "\n",
    "embedding_weights = np.array(embedding_weights)\n",
    "print('Load')\n",
    "\n",
    "# Embedding layer Initialization\n",
    "embedding_layer = Embedding(vocab_size + 1,\n",
    "                            embedding_size,\n",
    "                            input_length=input_size,\n",
    "                            weights=[embedding_weights])\n",
    "\n",
    "# Model Construction\n",
    "# Input\n",
    "inputs = Input(shape=(input_size,), name='input', dtype='int64')  # shape=(?, 1014)\n",
    "# Embedding\n",
    "x = embedding_layer(inputs)\n",
    "# Conv\n",
    "for filter_num, filter_size, pooling_size in conv_layers:\n",
    "    x = Conv1D(filter_num, filter_size)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    if pooling_size != -1:\n",
    "        x = MaxPooling1D(pool_size=pooling_size)(x)  # Final shape=(None, 34, 256)\n",
    "x = Flatten()(x)  # (None, 8704)\n",
    "# Fully connected layers\n",
    "for dense_size in fully_connected_layers:\n",
    "    x = Dense(dense_size, activation='relu')(x)  # dense_size == 1024\n",
    "    x = Dropout(dropout_p)(x)\n",
    "# Output Layer\n",
    "predictions = Dense(num_of_classes, activation='softmax')(x)\n",
    "# Build model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])  # Adam, categorical_crossentropy\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs=Input(name='inputs',shape=[max_len])\n",
    "    layer=Embedding(vocab_size,50,input_length=max_len)(inputs)\n",
    "    layer=LSTM(64)(layer)\n",
    "    layer=Dense(256,name='FC1')(layer)\n",
    "    layer=Activation('relu')(layer)\n",
    "    layer=Dropout(0.5)(layer)\n",
    "    layer=Dense(4,name='out_layer')(layer)\n",
    "    layer=Activation('softmax')(layer)\n",
    "    model1=Model(inputs=inputs,outputs=layer)\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 900)               0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 900, 50)           1350      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 48,458\n",
      "Trainable params: 48,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1=RNN()\n",
    "model1.summary()\n",
    "model1.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(train_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_train = train_data[indices]\n",
    "y_train = train_classes[indices]\n",
    "\n",
    "x_test = test_data\n",
    "y_test = test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 468 samples, validate on 83 samples\n",
      "Epoch 1/10\n",
      " - 15s - loss: 1.3853 - acc: 0.2692 - val_loss: 1.3860 - val_acc: 0.1928\n",
      "Epoch 2/10\n",
      " - 13s - loss: 1.3846 - acc: 0.2756 - val_loss: 1.3868 - val_acc: 0.1928\n",
      "Epoch 3/10\n",
      " - 13s - loss: 1.3833 - acc: 0.2650 - val_loss: 1.3869 - val_acc: 0.1928\n",
      "Epoch 4/10\n",
      " - 13s - loss: 1.3823 - acc: 0.2521 - val_loss: 1.3890 - val_acc: 0.1928\n",
      "Epoch 5/10\n",
      " - 13s - loss: 1.3794 - acc: 0.2799 - val_loss: 1.3903 - val_acc: 0.1928\n",
      "Epoch 6/10\n",
      " - 13s - loss: 1.3798 - acc: 0.2650 - val_loss: 1.3903 - val_acc: 0.1928\n",
      "Epoch 7/10\n",
      " - 13s - loss: 1.3812 - acc: 0.2500 - val_loss: 1.3890 - val_acc: 0.1928\n",
      "Epoch 8/10\n",
      " - 13s - loss: 1.3806 - acc: 0.2650 - val_loss: 1.3859 - val_acc: 0.1928\n",
      "Epoch 9/10\n",
      " - 13s - loss: 1.3800 - acc: 0.2863 - val_loss: 1.3843 - val_acc: 0.1928\n",
      "Epoch 10/10\n",
      " - 13s - loss: 1.3821 - acc: 0.2714 - val_loss: 1.3823 - val_acc: 0.1928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2dbbf44a90>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train, y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 468 samples, validate on 83 samples\n",
      "Epoch 1/50\n",
      " - 4s - loss: 1.3902 - acc: 0.2692 - val_loss: 1.3625 - val_acc: 0.3855\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1.3529 - acc: 0.3803 - val_loss: 1.1959 - val_acc: 0.6386\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1.1934 - acc: 0.5107 - val_loss: 1.0149 - val_acc: 0.6627\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.9921 - acc: 0.5897 - val_loss: 0.8983 - val_acc: 0.6867\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.8927 - acc: 0.6239 - val_loss: 1.0398 - val_acc: 0.6506\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.8523 - acc: 0.6496 - val_loss: 1.1490 - val_acc: 0.6747\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.8795 - acc: 0.6132 - val_loss: 0.9142 - val_acc: 0.6506\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.8809 - acc: 0.6560 - val_loss: 0.9097 - val_acc: 0.6867\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.7855 - acc: 0.6880 - val_loss: 0.6823 - val_acc: 0.6988\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6186 - acc: 0.7564 - val_loss: 0.7288 - val_acc: 0.7229\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.5827 - acc: 0.7607 - val_loss: 0.6239 - val_acc: 0.7831\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.5431 - acc: 0.8056 - val_loss: 0.7220 - val_acc: 0.7711\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.4640 - acc: 0.8184 - val_loss: 0.6421 - val_acc: 0.7590\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.4294 - acc: 0.8462 - val_loss: 0.9648 - val_acc: 0.6988\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.4518 - acc: 0.8355 - val_loss: 0.7559 - val_acc: 0.7590\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.3560 - acc: 0.8675 - val_loss: 0.8925 - val_acc: 0.7590\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.3167 - acc: 0.8868 - val_loss: 0.9108 - val_acc: 0.7711\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.3165 - acc: 0.8996 - val_loss: 1.0086 - val_acc: 0.7831\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.2688 - acc: 0.8932 - val_loss: 1.2308 - val_acc: 0.7590\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.2852 - acc: 0.9060 - val_loss: 1.1960 - val_acc: 0.7229\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.4197 - acc: 0.8440 - val_loss: 1.1777 - val_acc: 0.7831\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.4171 - acc: 0.8184 - val_loss: 0.9620 - val_acc: 0.7590\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.3629 - acc: 0.8632 - val_loss: 1.1801 - val_acc: 0.7711\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.3395 - acc: 0.8718 - val_loss: 0.9206 - val_acc: 0.7952\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.2242 - acc: 0.9081 - val_loss: 1.2475 - val_acc: 0.7349\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.2051 - acc: 0.9316 - val_loss: 1.2868 - val_acc: 0.7952\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.1440 - acc: 0.9444 - val_loss: 1.2797 - val_acc: 0.7349\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.1500 - acc: 0.9487 - val_loss: 1.5802 - val_acc: 0.7590\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.1404 - acc: 0.9380 - val_loss: 1.6088 - val_acc: 0.7831\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.1308 - acc: 0.9530 - val_loss: 1.6537 - val_acc: 0.7711\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.1031 - acc: 0.9637 - val_loss: 1.3342 - val_acc: 0.7711\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.1228 - acc: 0.9551 - val_loss: 1.7154 - val_acc: 0.7590\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.1144 - acc: 0.9573 - val_loss: 1.3516 - val_acc: 0.7349\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.0962 - acc: 0.9637 - val_loss: 1.6529 - val_acc: 0.7711\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.0741 - acc: 0.9722 - val_loss: 1.6489 - val_acc: 0.7470\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.0414 - acc: 0.9893 - val_loss: 1.6389 - val_acc: 0.7229\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.0424 - acc: 0.9872 - val_loss: 1.7061 - val_acc: 0.7590\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.0258 - acc: 0.9936 - val_loss: 1.8183 - val_acc: 0.8072\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.0302 - acc: 0.9872 - val_loss: 1.8870 - val_acc: 0.7831\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.0159 - acc: 0.9936 - val_loss: 2.0663 - val_acc: 0.7711\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.0189 - acc: 0.9915 - val_loss: 2.2292 - val_acc: 0.7711\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.0212 - acc: 0.9936 - val_loss: 2.2151 - val_acc: 0.7711\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.0274 - acc: 0.9915 - val_loss: 2.0163 - val_acc: 0.7470\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.0217 - acc: 0.9893 - val_loss: 2.0755 - val_acc: 0.7470\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.0264 - acc: 0.9915 - val_loss: 2.0609 - val_acc: 0.7470\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.0151 - acc: 0.9936 - val_loss: 2.0381 - val_acc: 0.7470\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.0470 - acc: 0.9850 - val_loss: 2.0384 - val_acc: 0.7952\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.0545 - acc: 0.9786 - val_loss: 2.1781 - val_acc: 0.7470\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.0674 - acc: 0.9744 - val_loss: 2.1655 - val_acc: 0.7952\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.0710 - acc: 0.9658 - val_loss: 2.0048 - val_acc: 0.7711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2e8f795588>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "y_prob = model.predict(x_test) \n",
    "y_classes = y_prob.argmax(axis=-1)\n",
    "print(len(y_classes))\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 3 0 3 0 1 1 2 2 0 0 0 3 1 3 3 0 3 0 1 0 2 0 0 2 2 3 3 0 1 1 3 1 0 1 2\n",
      " 0 2 2 2 1 3 1 2 3 1 0 3 2 1 1 3 0 2 0 2 0 2 2 2 0 0 3 3 0 3 0 0 0 3 0 3 0\n",
      " 2 3 3 2 2 2 0 3 3 1 3 1 0 3 1 2 0 2 3 0 1 3 0 1 3 2 3 0 0 3 0 0 0 1 2 1 0\n",
      " 2 0 3 1 2 1 0 1 1 1 2 0 0 0 2 0 0 2 0 2 1 2 2 2 2 1 3 2 2 3 1 1 0 2 3 2 1\n",
      " 2 1 2 0 3 0 2 2 3 0 1 2 1 1 3 2 0 1 2 2 1 3 2 2 3 1 0 0 0 0 2 1 3 3 3 1 3\n",
      " 3 1 2 3 0 0 2 1 1 1 3 0 3 1 1 3 0 3 3 0 0 2 0 2 1 2 0 1 2 1 1 1 2 1 0 1 3\n",
      " 2 1 2 3 0 1 2 3 0 2 1 3 1 0 3 1 3 3 0 1 2 3 1 0 2 0 0 1 0 2 1 0 2 0 2 3 0\n",
      " 1 0 0 0 3 3 0 2 0 0 0 2 3 1 1 0 1 2 2 3 1 0 0 3 0 1 1 2 2 0 0 0 3 3 1 2 2\n",
      " 1 3 2 3 3 1 0 1 1 1 0 0 1 0 2 2 2 1 0 3 0 0 0 0 2 1 2 1 3 0 1 3 2 2 2 3 1\n",
      " 2 2 0 0 1 2 0 0 3 1 3 3 3 1 3 1 0 2 2 1 1 1 0 0 3 1 0 2 1 2 3 0 3 0 0 2 2\n",
      " 0 3 1 2 0 0 2 2 2 0 0 3 1 0 2 0 3 1 0 3 0 1 1 1 2 1 2 0 1 2 0 2 2 1 1 0 2\n",
      " 3 1 3 1 0 1 2 1 1 0 1 1 2 2 1 2 3 2 3 3 3 1 3 0 0 2 3 2 1 2 2 1 2 0 0 1 2\n",
      " 2 0 2 0 0 2 2 3 1 3 0 2 2 3 0 0 0 3 2 1 1 1 2 3]\n",
      "193    2\n",
      "248    2\n",
      "277    2\n",
      "320    3\n",
      "374    3\n",
      "175    2\n",
      "279    2\n",
      "502    4\n",
      "323    3\n",
      "401    3\n",
      "110    1\n",
      "227    2\n",
      "172    2\n",
      "127    1\n",
      "107    1\n",
      "290    2\n",
      "99     1\n",
      "268    2\n",
      "478    4\n",
      "364    3\n",
      "212    2\n",
      "220    2\n",
      "402    3\n",
      "379    3\n",
      "66     1\n",
      "479    4\n",
      "264    2\n",
      "377    3\n",
      "387    3\n",
      "23     1\n",
      "      ..\n",
      "22     1\n",
      "456    4\n",
      "495    4\n",
      "245    2\n",
      "440    4\n",
      "239    2\n",
      "134    1\n",
      "112    1\n",
      "466    4\n",
      "354    3\n",
      "293    2\n",
      "523    4\n",
      "403    3\n",
      "347    3\n",
      "164    2\n",
      "338    3\n",
      "321    3\n",
      "42     1\n",
      "29     1\n",
      "185    2\n",
      "500    4\n",
      "260    2\n",
      "412    3\n",
      "20     1\n",
      "186    2\n",
      "488    4\n",
      "375    3\n",
      "210    2\n",
      "81     1\n",
      "276    2\n",
      "Name: class_no, Length: 83, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_prob1 = model.predict(x_train) \n",
    "y_classes1 = y_prob1.argmax(axis=-1)\n",
    "print(y_classes1)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_y[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,dummy_y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=int(data['pattern'].str.len().max())\n",
    "print(max_len)\n",
    "min_len=int(data['pattern'].str.len().min())\n",
    "print(min_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 4\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(4,name='out_layer')(layer)\n",
    "    layer = Activation('softmax')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(sequences_matrix,Y_train,batch_size=1,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class=mode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
